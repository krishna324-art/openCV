{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "load resnet50 trained on imagenet50 -> normalize images-> load shap for explainer for image-> analayze the features/pixels of image contributing to classification\n"
      ],
      "metadata": {
        "id": "YLnS6Z4A-lxo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install shap tensorflow"
      ],
      "metadata": {
        "id": "KPu0gCjR_Awr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50,preprocess_input\n",
        "import shap\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "3ZccsCbB_Qer"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#load pre-trained model and data\n",
        "model=ResNet50(weights=\"imagenet\")\n",
        "X,y=shap.datasets.imagenet50()"
      ],
      "metadata": {
        "id": "pnQCmySU_zOI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(y)"
      ],
      "metadata": {
        "id": "FTdH4gaZWmUm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(X[20])"
      ],
      "metadata": {
        "id": "tomxXUguIOeW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X[20])"
      ],
      "metadata": {
        "id": "h4tWapyiIcug"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#scaling the image\n",
        "#assume that  image contains data needs to be sacled to range[0,255]\n",
        "X=np.clip(X,0,255).astype(np.uint8)\n"
      ],
      "metadata": {
        "id": "CMW6ubX-ANb2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(X[2])"
      ],
      "metadata": {
        "id": "CH3-MdsoItxB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X.shape)"
      ],
      "metadata": {
        "id": "WUso2BmiJV8O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#getting the 1000 class names\n",
        "url=\"https://s3.amazonaws.com/deep-learning-models/image-models/imagenet_class_index.json\"\n",
        "with open(shap.datasets.cache(url)) as file:\n",
        "  class_names=[v[1] for v in json.load(file).values()]"
      ],
      "metadata": {
        "id": "K0EU6rhHJ8LO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"number of imagenet classes:\",len(class_names))\n",
        "print(\"class names:\",class_names)"
      ],
      "metadata": {
        "id": "qKxgviYWKsXi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def f(x):\n",
        "    # Preprocess the input x directly, not the global X\n",
        "    return model.predict(preprocess_input(x))\n",
        "\n",
        "#define a masker that is used to mask out partitions of the input image\n",
        "masker=shap.maskers.Image(\"inpaint_telea\",X[0].shape)\n",
        "#create an explainer with model and image masker\n",
        "explainer=shap.Explainer(f,masker,output_names=class_names)\n",
        "#here we explain two images using 1oo evaluation of underlayingmodl to estimate the SHAP values\n",
        "shap_values=explainer(X[1:3],max_evals=100,batch_size=50,outputs=shap.Explanation.argsort.flip[:4])"
      ],
      "metadata": {
        "id": "O8PFqdJrK5XI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# output with shap values\n",
        "# this highlighted group of pixels making it look like what predictions\n",
        "\n",
        "shap.image_plot(shap_values)\n",
        "\n",
        "# Save the plot as a static image for GitHub compatibility\n",
        "import matplotlib.pyplot as plt\n",
        "plt.savefig('shap_image_plot_inpaint.png', bbox_inches='tight')"
      ],
      "metadata": {
        "id": "vAyhmOUXUlga"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def f(x):\n",
        "    # Preprocess the input x directly, not the global X\n",
        "    return model.predict(preprocess_input(x))\n",
        "\n",
        "#define a masker that is used to mask out partitions of the input image\n",
        "masker=shap.maskers.Image(\"blur(128,128)\",X[0].shape)\n",
        "#create an explainer with model and image masker\n",
        "explainer=shap.Explainer(f,masker,output_names=class_names)\n",
        "#here we explain two images using 1oo evaluation of underlayingmodl to estimate the SHAP values\n",
        "shap_values_fine=explainer(X[1:3],max_evals=500,batch_size=50,outputs=shap.Explanation.argsort.flip[:4])"
      ],
      "metadata": {
        "id": "G0fH_VSMX1mX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shap.image_plot(shap_values_fine)\n",
        "\n",
        "# Save the plot as a static image for GitHub compatibility\n",
        "import matplotlib.pyplot as plt\n",
        "plt.savefig('shap_image_plot_blur.png', bbox_inches='tight')"
      ],
      "metadata": {
        "id": "1yHCEPRnd9nJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NkvQB1TYeIpe"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}